# 항해 Lite 백엔드 코스 - e-커머스 서비스

## 🎯 프로젝트 개요
- `e-커머스 상품 주문 서비스` 입니다.

## 개발 환경
- SpringBoot 3.4
- Java 17

## Docs
- [API 명세서](./docs/api_spec.md)
- [ERD](./docs/erd.md)
- [인프라 구조도](./docs/infra_structure.md)


---
### 핵심 기능
- ✅ 회원 관리 (가입/로그인/포인트 충전/사용)
- ✅ 상품 조회 및 재고 관리 (동시성 제어)
- ✅ 주문/결제 처리 (트랜잭션 보장, 중복 방지)
- ✅ 쿠폰 발행 및 사용 (선착순 제한, 동시성 제어)
- ✅ Outbox 패턴을 통한 이벤트 발행 안정성 보장


---
### 아키텍처 개요
<img src="./docs/image/인프라구조도.png">

---
### 요청 처리 흐름
1. 사용자 요청
2. WAS로 접근
3. 비즈니스 로직 처리(RDB 및 Redis 조회)
4. 응답 반환


## 아키텍처 결정 기록 (ADR)

---
### ADR-001 : e-commerce 애플리케이션 개발 언어 및 프레임워크 선택
**문제점**
- e-commerce 애플리케이션 개발에 필요한 언어와 프레임워크 선택 필요

**결정**
- java/spring 선택

**근거**
- 개발자(나)의 언어와 프레임워크에 대한 이해도가 java와 spring 에 대한 이해도가 보다 높기 때문에 해당 언어와 프레임워크를 선택.
- 안정적인 생태계와 커뮤니티 지원
- 대규모 애플리케이션 확장성 우수

📄 [상세 내용](docs/infra_structure.md#adr-001--e-commerce-애플리케이션-개발-언어-및-프레임워크-선택)

---
### ADR-002 : MySQL 도입
**문제점**
- 애플리케이션의 데이터를 저장할 RDB 선택 필요

**결정**
- MySQL 선택

**근거**
- 안정적인 생태계와 커뮤니티 지원
- 개발자(나)가 RDB 중 MySQL에 가장 친숙함.

**대안**
- MariaDB
- Oracle
- PostgreSQL

📄 [상세 내용](docs/infra_structure.md#adr-002--mysql-도입)

---
### ADR-003 : Docker 도입
**문제점**
- 로컬 개발 환경과 프로덕션 환경의 불일치로 인한 배포 복잡도 증가

**근거**
- 개발/프로덕션 환경 통일
- 빌드와 배포 자동화 가능
- 향후 Kubernetes 확장성 고려

**대안**
- 도커를 사용하지 않고, 온프레미스에서 직접 서버를 띄울 수도 있다.
- 하지만, 추후 클라우드로 도입 혹은 Kubernetes의 확장성을 고려하여, 도커를 적극적으로 도입함.

📄 [상세 내용](docs/infra_structure.md#adr-003--docker-도입)

---
### ADR-004 : Redis 도입

**문제점**
- 결제 중복 요청을 방지하기 위해 header에 `idempotency_key` 를 넣음.
- 해당 키를 통해 요청된 결제가 중복 결제인지를 체크하는 과정이 필요했음

**근거**
- 이미 많이 사용되기도 하고, 또한 메모리 DB로써 빠른 속도를 내기 때문에, 사용하기로 결정

**대안**
- DB를 통해 구현할 수도 있지만, DBC를 낭비하게 되고, 네트워크 비용도 있고, 속도도 Redis보다 느림
- 이후에 적용될 기능을 위해 필요하기 때문에, Redis를 도입하게 됨

📄 [상세 내용](docs/infra_structure.md#adr-004--redis-도입)
---

### 각 챕터마다 배운 것

<details>
<summary> <b> Step 1. TDD 기본다지기</b> </summary>

### 기술적 성장

- 새로 학습한 개념
  - 행위 검증에서 then.should 절이 쓰인다는 것 
  - 호출 여부가 중요할 때 사용한다는 것 
  - Mocking을 했을 때 메서드 내부에서 호출하는 메서드를 Stub 해줘야하는 것 
  - given절에서는 matcher(eq, anyXX)를 사용하지만, willReturn에서는 matcher가 아닌 실제 값을 넣어줘야하는 것 
- 기존 지식의 재발견/심화 
- @ExtendWith(MockitoExtension.class) 와 @WebMvcTest 차이 그리고 @mock과 @MockBean의 차이 를 알 수 있었고,
  - @WebMvcTest 와 @MockBean을 사용하는 것보다 @ExtendWith(MockitoExtension.class) 와 @mock을 사용하는 것이 더욱 빠르다는 것.
- 행위 검증/상태 검증이 있는 것 -> 기존에 자주 쓰던 assert는 상태 검증을 하는 것

- 규칙 정리 
  - 하나에 한 책임 
  - 외부 의존성 처리 
  - 테스트는 재현 가능해야함(랜덤/시간 의존 제거 -> 고정된 수치)
  - 명확한 테스트 이름 
  - `Assertions`은 명확하게 
    - 보다 크다 X
    - "="
  
- 안티패턴
  - 테스트 간 상태 공유 X
  - sleep 사용 X
    - 비동기 처리 대기 시 Awaitillity 라이브러리 등 사용 X
  - 의미 없는 이름X
  - 과도한 Mock 검증
    - 내부 구현을 너무 상세히 검증하기 보단 외부로 보이는 결과에 집중하도록

- 알게된 내용들
  - 상태검증(Assert)/행위검증(then/should)
    - GPT가 둘 다 해야된다고 알려주긴했지만, 둘 다 작성할 때도 있고, 상태가 중요하다면 상태를, 호출 여부가 중요하면 행위 검증을
  - BDDMockito
    - 검증 절에서 verify 대신 then 쓰면 더 가독성이 좋다
  - then.should 체이닝 가독성이 좋다.
  - then하고 should() 함수에 인자를 안주면 1회 호출을 검증
    - 호출을 안했다는 것을 검증하려면 should(never())
    - 만약 여러 번 호출 검증은 should(times(n))
  - 비동기 호출이나 이벤트 검증은 이벤트 관련 테스트도 가능
    - 대부분 호출 여부만 보면 된다
  - 만약 통합으로 보면 DB 접근과 같은 외부 사용시 Mocking 하거나 스텁을 사용하면 된다.
  - ArgumentCaptor를 쓰지말고, anyXX 를 활용하자
  - eq() 를 사용해서 특정 값을 좁혀놓는것도 안정성에 좋다
  - 테스트 코드 작성시 굳이 하지 않아도 될 테스트는 하지 않아도 된다.
    - 예를 들어, RequestParam 에서 Long으로 받기로 되어있는데, 문자열로 들어올 때 스프링이 걸러주는지를 테스트 하는 경우
      - 스프링이 알아서 걸러주기 때문에 굳이 하지 않아도 되는 테스트 케이스이다.
  - given , when , then 에도 명확하게 주석 달기
  - 하나의 케이스에서 여러 검증을 수행하는 경우 @nested를 활용할 수 있다.

- 추후 해볼 것!
  - given // when // then 명확히 주석으로 나누기
  - 서비스 레이어 명확히 주석으로 나누기
  - then should
  - 동시성 고려하기
</details>


<details>
<summary> <b>Step 2. 서버 구조 설계</b> </summary>

- 깨닫게 된 것
  - 문서가 중요
  - 설계는 곧 문서로 나타남

- 배운 것
  - 문서대로 개발 진행
  - 설계가 잘 되어있으면 개발은 스무스함.

**중요**
- 필요한 모든 내용이 들어가 있는가
  - 필요한 내용은 모두 들어가 있어야 한다.
    - 실제 설계한 문서와 설계도를 가지고 개발을 하려면 개발 과정에서 어떤 기술을 사용하고, 어떤 스펙으로 이 서버가 구성되는지 제대로 들어가있어야 함.
- 필요한 내용만 들어가 있는가
  - 지금 생각하고 있는 서비스가 있는데 범위를 넘어서 지금은 아니지만, 나중엔 필요할 거 같은 판단되는 기능 "정말 확실하게 필요한 케이스는 모르겠지만, 잘은 모르지만, 뭔가 있어야될 거 같은.. 명확하지 않은 것"을 설계에 포함하면, 실제로 설계를 했더라도 개발 과정에서 어려움을 느낄 수 있다.
  - 설계가 깔끔하게 되어있으면 개발은 스무스하게 넘어간다. 설계 문서를 그대로 따라가기 때문이다. 그러나 필요한 내용만 들어가있지 않으면 이런 내용이 점점 모호해진다. 그렇기 때문에 내가 이해한 필요한 내용만 있어야 한다.
- 모든 구성 요소를 이해하고 있는가
  - 예를 들어, 인프라 구성도에서 "대용량 처리 시스템에는 카프카가 있어야하는데, 나는 카프카를 모르지만 어쨌든 넣는다" 이런 것은 지양해야한다. 왜냐하면 실제로 당장 써먹을 수 없는 설계도이기 때문이다.
- 협업을 고려한 문서인가
  - 내가 설계한 문서가 적합한지, 개선할 것은 없는지, "우리 시스템이 이렇게 구현될것이다" 라는 의미로도 쓰일 문서이다.
  - 다른 사람이 읽기 불편하지 않아야 하는 그런 문서가 되지 않아야하고, 나만 아는 단어가 되면 안 된다.


#### 멘토님이 생각하는 설계 FLOW**

   1. 무조건 있을 수 밖에 없는 기능을 생각한다. -> 예를 들어, e-commerce라면 상품 조회 / 구매 / 포인트 충전 등등 
   2. API 명세
   3. ERD
   4. 인프라 구조도
   5. 서비스에서 특별히 붙여야되는 기능을 정리한다.
      -> 여기에 맞춰서 2, 3, 4 를 지속적으로 업데이트한다.


- 코치님은 개인적으로 DB가 데이터를 정하는 것을 선호하지 않음.(예를 들면 auto increment가 될 수 있음)
  - 애플리케이션 내의 비즈니스로직으로 컨트롤하는 것을 선호함. 
  - 일단 나도 코치님 따라 해보는 것으로 하기
- 모든 선택의 근거가 있어야함(찾는 것 아님)
- ERD가 API 명세는 충족하지만 API 명세가 ERD를 충족하지 못할 수도 있다.
  - 예를 들어 유저의 성별이 M | F 로 enum 처리를 할 수도 있지만 이후 사회적 이슈에 따라 유저를 표기하지 않을 수도 있고 없는 경우도 있다.
  - 따라서 API 명세로는 그렇게 되어있지만 ERD 상으론 열려있는 구조가 되어야 한다
- 문서는 시간이 지나서 계속 바뀔 수 밖에 없다. 
  - 처음부터 완벽할 수 없다.
- 인프라 구조도에서 app의 ip로 접속하기보단 앞에 DNS를 통해서 프론트 개발자가 쉽게 접근할 수 있도록 한다. 
- 개발 언어와 스택, DB 같은 경우에도 선택의 이유가 있어야한다.
  - 우리 팀이 해당 언어 및 프레임워크에 대한 이해가 높다)
- ERD에서 애매모호할 땐 일단은 STRING으로 지정한다.
  - STRING에서 INTEGER로 변환하는 것은 쉽지만 반대의 경우 INTEGER로 했다가 해당 값에 문자열이 들어가면 그렇게 변환하는 것은 쉽지 않다


- 개선할 것
  - API 명세 : 조금 더 디테일하게 (일단은 ai 피드백 필요)
  - 인프라 구조도 : 지금 redis가 필요 없음
  - 도메인 
    - 회원
      - 역할 : 구매자 / 판매자 : 기본 구매자, 회원의 의사에 따라 판매자도 가능

</details>

<details>
<summary> <b>Step 3. 클린 아키텍처로 안정성 확보</b> </summary>

### 클린 아키텍처 특징
  - 의존성 방향이 외부에서 내부로 간다.
  - 애플리케이션 내부에서는 외부에 어떤 일이 발생했는지 알 수 없다.
  - 도메인 객체가 프레임워크에 종속되지 않고, 독립적이다.
  - 프레임워크에 종속적이지 않아 테스트가 용이하다.
- 단점
  - JPA의 좋은 기능인 변경감지를 잘 활용하지 못한다.
  
근데, 현재 아직은 잘 모르겠다..
좀 더 사용해봐야할 듯

### 해당 STEP에서 한 것

#### 1. Controller에서 요청 값에 대해 검증할 때, ArgumentProvider를 도입

- 기존의 MockMvc를 통해서 요청에 대한 값을 검증했었다.
- 그런데, 일일이 given에서 값을 세팅하고, when then 절에서 `mockMvc.perform` 을 계속 하다보니 귀찮았다.
- 테스트는 애플리케이션의 개발 속도를 증가시켜줘야 하는데, 필드가 하나씩 늘어날 때마다 계속해줘야했다.
- 이 때 ArgumentProvider를 도입함으로써 요청 값에 대한 검증 테스트가 훨씬 간결해졌다.

#### 2. 주문과 결제 로직 분리

- 기존에는 주문 로직에 결제와 관련된 모든 로직을 때려넣었다.
- 그런데, 주문에 대한 로직에 너무 많은 책임이 있었고, 결제 로직에서 해도 될 부분이 주문 로직에 포함이 되어있었다.
- 클린 아키텍처 구조로 변경하려고 했는데, 주문에 책임이 너무 많이 몰려있다보니, 분리하게 되었다.
- 주문 / 결제를 분리하고 보니 클린 아키텍처로 구조 변경하는 것이 매우 쉬워졌다.

#### 3. 주문 로직에 클린 아키텍처 도입

- 패키지 구조가 3개에서 4개로 늘어났다.
- controller, service, repository 구조에서 interfaces, application, domain, infrastructure 구조로 변경되었다.

- interfaces 에서 클라이언트로부터 요청을 받고, 요청은 application 으로 가게된다.
- application에서 domain으로 향하게 되고, domain에서는 domain 로직을 수행한 후, 다시 application으로 향하게 된다.
- application에서는 infrastructure 로 향하게 되고, infrastructure는 외부에서 해야할 일을 수행한 다음, interfaces 로 응답을 보내게 된다.



### 이후 해야될 것

1. 쿠폰 관련 기능 추가
2. 현재 하나의 주문에 하나의 상품과 수량만 받지만 여러 개를 받을 수 있도록 해야한다.
3. 현재 각 도메인의 Id는 Long 타입으로 받고 있다. 이를 UUID, 혹은 복잡한 Id를 사용하도록 해야한다.
4. 다른 도메인도 클린 아키텍처 구조로 변경해야 한다.
5. 회원과 관련된 기능 추가(JWT 도입, 가입, 로그인 등등)


### 의문점

#### 1. 서비스 계층에서 @Service를 빼야한다고 함.

- 서비스 계층에서 @Service를 빼야한다고 한다. 하지만, @Service를 빼면 @Bean으로 등록해야한다.
- 스프링에 종속되지 않게 하기 위해서 @Service를 빼는 건데, 결국은 애플리케이션을 사용할 때는 얘를 Bean으로 올려야 한다. 
- 그럼 결국 스프링에 종속되는 건데... 이게 맞나??

**클로드 코드한테 물어보고 얻은 답 정리**
- 어차피 스프링을 씀.
  - 따라서 **독립/종속적보다는 의존성 방향이 중요.**
- POJO로 하고, Bean으로 올린다고 해도, 결국 의존하는 객체도 결국 스프링 컨텍스트에 올라가야 함.
  - 테스트도 의존하는 객체를 Mock 처리해야 함.
- 그냥 @Service를 붙이자.

### 느껴야하는 것.

- SOLID를 느껴야 함.
  - 아직은 안 느껴짐.
  - 현재 나는 클린 아키텍처에 대한 이해도 아직 떨어짐..


## 라이브 세션

**라이브 세션 주제**
- 너무 많은 것을 담으려고 하지 말자
- 아키텍처라는 것의 의의를 이해하기
- '클린'하다는 것이 무엇인지 설명할 수 있는가?


**큰 주제**
- 너무 많은 것을 담으려고 하지말자.
- 아키텍처라는 것의 의의를 이해하기
- '클린'하다는 것이 무엇인지 설명할 수 있는가?

#### 아키텍처

- 아키텍처가 왜 나왔는지 알아야 한다.
  - Layered Architecture은 1980년대에 나옴(참고)
- 아키텍처는 약속이다.

#### 클린 아키텍처

- 클린 아키텍처는 처음에 도입했을 때 "잘 적용되어 있는 것이 맞는가?"라는 의문이 드는 것이 맞다.
  - 이후에 클린 아키텍처에 대한 철학과 배경을 이해하게 되면서 잘 적용되었는지 판단할 수 있다.

- **중요한 것**
  - UseCase 와 Entity가 가장 안쪽에 있는가(순수한가)
  - UseCase 와 외부세계가 완벽하게 분리되어 있는가?

#### 세션 이후 내가 해야할 것

- core 주문 로직만 클린 아키텍처로 적용하는 것이 요구사항이었고, 제대로 된 것이 맞는지 의아했다.
- 결론은 제대로 된 것이 아니다.
  - 주문은 잘 했어도, 주문 로직에서 회원 조회, 상품 조회는 여전히 외부 세계(DB)와 완벽하기 분리되어있지 않고, JPA를 애매하게 사용하고 있다.
  - 이후 해야할 것은 core 쪽을 clean 하게 유지보수 하는 것이다.

#### 클린 아키텍처로 구조 변경 하면서 느낀 점

- 테스트 코드가 좀더 도메인 중심의 코드로 변경되고 있다.
  - 되게 편하다.
  - 특히 Mocking 처리할 때, 일일이 Id를 `Utils.setId()` 같은 메서드를 사용해서 Id를 주입해야해줬지만, 지금은 그냥 `member.assignId(id)` 같은 도메인 모델의 메서드를 사용하고, 이를 `willReturn()` 절에 바로 넣을 수 있어서 되게 편하다. 
- 구조 변경 중인데, 당연한 말이지만, 그만큼 테스트 코드를 건드려야할 부분이 많다.
  - 특히 반복적으로 given절을 많이 손대는 게 좀 귀찮긴한데, 이후, 이 부분을 따로 private 메서드로 뽑아서 편리하게 사용하도록 해야겠다.
- 구조 변경하는 게 쉽지가 않다. 특히 테스트 코드까지 손봐야하는 경우, 오래 걸린다. 하지만, 계속 하게 되면, 빠르게 할 거 같지만,, 뛰엄뛰엄 하려하니 쉽진않다.


</details> 

<details>
<summary> <b>Step 4. DB 구조로 데이터 정합성 확보</b> </summary>

### 해당 스텝에서 배운 것
- 데이터 모델링
- 락과 동시성 전략
- 인덱스 및 쿼리 설계
- 읽기 스케일아웃 및 복제 지연
- 파티셔닝과 샤딩
- CQRS와 Outbox

### 해당 스텝에서 한 것
- 모든 도메인을 클린 아키텍처 구조로 변경
- 각 도메인의 비즈니스 로직 테스트 작성
- Presentation 계층에서의 요청값 검증 방식 변경 
  - 일일이 given.when.then 에서 ArgumentProvider 를 사용하는 방식으로 변경
- 쿠폰 도메인 기능 구현
  - 쿠폰 생성
  - 쿠폰 조회
  - 쿠폰 발행
- 주문/결제 로직 분리
- 주문/결제 시 Outbox 패턴 적용
  - 외부 메세지 전송 실패시 결제 정보 outbox 테이블에 저장
- 결제 중복 요청 방지
  - idempotency_key를 사용함으로써 결제 중복 요청 방지 완료 및 테스트 완료 

### 얻은 것
- 클린 아키텍처 구조에 익숙해짐
  - 하지만 여전히 잘 짜여진 구조인지는 의문임.
- 복잡한 비즈니스 로직 구현
  - 실무에서 코딩을 하지 않아 익숙지가 않은 거 같음..**빨리 이직해야함**
- RestAssured 를 사용해서 API 통합테스트가 가능하다는 것
- 여러 쓰레드로 동시성 통합테스트 작성

### 이후 해야할 것
- 결제 취소 구현
- 결제 취소에 따른 재고 복원 구현해야 함.


## 라이브 세션
- 전반적으로 DB에 관한 세션이었고, RDB에 관한 말들을 많이 해주셨다.
- 다행인 것은 해당 세션에 대한 생각이 코치님과 같았다: 애매하다..


## 이후 해볼 것
- 인덱스 설계 
- 배운 것에 대한 개념 복습


## 해보기 전에 내가 알아야 하는 것
- 인덱스에 대한 학습이 필요하다.


**총평** : 갈길이 멀다.... 

</details>


<details>
<summary> <b>Step 5. 동시성 제어</b> </summary>

### 해당 스텝에서 배운 것
- Pessimistic Lock (비관적 락) 개념 및 활용
  - `@Lock(LockModeType.PESSIMISTIC_WRITE)` 사용법
  - Lock 경합 상황에서의 대기 메커니즘
- Redis 기반 Idempotency Key 패턴
  - `SET NX` 명령어를 통한 원자적 중복 체크
  - TTL을 활용한 키 자동 정리
- 동시성 문제 유형
  - Lost Update: 동시 수정으로 인한 데이터 손실
  - Race Condition: 읽기-수정-쓰기 과정에서의 경합
  - Check-Then-Act: 검증과 실행 사이의 시간 차이
- 멀티스레드 테스트 패턴
  - ExecutorService + CountDownLatch 활용
  - AtomicInteger를 통한 성공/실패 카운팅

### 해당 STEP에서 한 것
- **Point (포인트) 동시성 제어 구현**
  - `PointJpaRepository.findByMemberIdForUpdate()` 추가 (Pessimistic Lock)
  - ChargePointService, UsePointService, PointPayment에서 Lock 메서드 사용
  - 충전/사용/결제 시 모든 포인트 변경에 Lock 적용

- **Stock (재고) 동시성 제어** (기존 완료)
  - `StockJpaRepository.findByProductIdForDeduct()` (Pessimistic Lock)
  - 재고 부족 시 Lock 획득 실패로 예외 발생

- **Coupon (쿠폰) 동시성 제어** (기존 완료)
  - `CouponJpaRepository.findByCouponIdForIssue()` (Pessimistic Lock)
  - 발행 한도 초과 시 Lock 획득 실패

- **Payment (결제) 중복 방지** (기존 완료)
  - Redis Idempotency Key 패턴 적용
  - Header의 `idempotency_key`로 중복 요청 차단

- **멀티스레드 테스트 작성**
  - Point: 4개 시나리오 (동시 충전, 동시 사용, 혼합, 부족)
  - Stock: 2개 시나리오 (정상 차감, 재고 부족)
  - Coupon: 1개 시나리오 (선착순 발행)
  - 모든 테스트 통과 (데이터 정합성 100% 보장)

- **동시성 제어 보고서 작성**
  - `docs/동시성_제어_보고서.md` 작성
  - 문제 상황, 해결 전략, 구현 상세, 테스트 결과, 성능 분석, 운영 고려사항 포함

### 얻은 것
- **데이터 정합성 우선 사고방식**
  - 금융 데이터는 1원의 오차도 허용되지 않음
  - 성능보다 정합성이 최우선
  - 성능은 모니터링 후 점진적으로 개선

- **Lock 전략 선택 기준**
  - Pessimistic Lock: 데이터 정합성이 최우선일 때
  - Optimistic Lock: 충돌이 적고 재시도가 허용될 때
  - Redis: 분산 환경에서 빠른 중복 체크가 필요할 때

- **멀티스레드 테스트의 중요성**
  - 단위 테스트만으로는 동시성 문제를 발견할 수 없음
  - 극한의 동시성 상황을 테스트해야 실제 버그 발견 가능
  - ExecutorService로 100개 이상의 스레드 동시 실행 검증

- **트레이드오프 이해**
  - Lock으로 인한 성능 저하 (4-5배) 수용
  - 샤딩, 캐시 등으로 성능 개선 가능
  - 간단한 구현 > 복잡한 최적화 (유지보수성 우선)

### 이후 해야할 것
- **성능 최적화**
  - Lock 대기 시간 모니터링 (APM 도구 도입)
  - Lock 범위 최소화 (필요한 구간만 Lock)
  - 트랜잭션 시간 단축 (불필요한 로직 제거)

- **데드락 방지**
  - Lock 획득 순서 통일 (Stock → Coupon → Point)
  - 데드락 발생 시 알림 시스템 구축
  - `innodb_lock_wait_timeout` 설정 최적화

- **분산 환경 대비**
  - Redis 고가용성 (Sentinel, Cluster)
  - 분산 락 라이브러리 검토 (Redisson)
  - 이벤트 소싱 패턴 검토

- **모니터링 강화**
  - Lock 대기 시간 추적
  - 동시 요청 수 모니터링
  - Redis 응답 시간 추적

### 의문점

#### 1. Pessimistic Lock이 항상 정답인가?
**생각 정리**
- Pessimistic Lock은 데이터 정합성을 100% 보장하지만 성능 저하가 있음
- 충돌이 적은 경우 Optimistic Lock이 더 효율적일 수 있음
- 하지만 e-commerce에서는 충돌이 빈번하므로 Pessimistic Lock이 적합
- 결론: **도메인 특성에 따라 선택**해야 함

#### 2. Lock 범위를 어디까지 줄여야 하는가?
**생각 정리**
- 현재는 전체 트랜잭션에 Lock이 걸려 있음
- 이론적으로는 읽기-수정-쓰기 구간만 Lock을 걸어야 함
- 하지만 트랜잭션 중간에 Lock을 걸면 데드락 위험 증가
- 결론: **안정성 우선**, 성능 문제 발생 시 점진적으로 범위 축소

#### 3. Redis 장애 시 결제가 중단되는가?
**생각 정리**
- 현재 구현은 Redis 연결 실패 시 예외 발생
- Fallback으로 데이터베이스 기반 중복 체크 가능
- 하지만 Fallback 로직이 복잡해지고 일관성 유지 어려움
- 결론: **Redis 고가용성 구성**(Sentinel, Cluster)이 더 나은 해결책

#### 4. 멀티스레드 테스트가 실제 운영 환경을 반영하는가?
**생각 정리**
- 로컬 테스트는 단일 서버, 동일 프로세스 환경
- 실제 운영은 분산 서버, 네트워크 지연 존재
- 분산 환경에서는 다른 문제가 발생할 수 있음
- 결론: **멀티스레드 테스트는 기본**, 추가로 부하 테스트 필요

**총평**
- 동시성 제어는 이론과 실습의 간극이 큰 영역
- 멀티스레드 테스트를 통해 실제 문제를 직접 경험하고 해결함
- **데이터 정합성은 타협할 수 없는 영역**임을 깨달음
- 향후 실무에서도 동시성 문제를 우선적으로 고려하는 개발자가 되어야겠음


## 라이브 세션

- 동시성 이슈는 병렬처리 되는 포인트에서 일어난다
- 락 = 부분적인 직렬처리
- 안전의 책임을 어디에 둘것인가?

</details>


<details>
<summary> <b>Step 6. 분산락과 캐싱으로 트래픽 대응</b> </summary>

### 해당 스텝에서 배운 것

- 분산 락을 Redis로 구현할 수 있다.
  - Redis의 `SET NX`를 통해 구현할 수 있다.
    
    
- Redis
  - Redis는 메모리 기반의 key-value 스토어다.
  - 메모리에 있기 때문에 빠르다.
  - Redis는 데이터의 영속성을 보장하지 않는다.
  - Redis를 통해 분산 락을 구현할 경우엔, Redis가 절대 떨어지면 안 된다.
    - Locking 정보를 담고 있으므로, 가용성과 영속성이 보장되어야 하기 때문이다.
    - 그래서 클러스터 형태로 구현한다.

- 분산 락은 애플리케이션에서 락을 제어한다.
- DB-lock은 DB에서 락을 제어한다.


### 해당 스텝에서 한 것

- 동시성 이슈가 발생할 수 있는 곳(재고, 쿠폰, 포인트)에 분산락 적용

### 해당 스텝에서 얻은 것

- 분산 락을 적용이 생각보다 어렵다는 것
  - 어려운 이유는 비즈니스 로직에서 처리해야할 것이 복잡하다면, 그에 따라 트랜잭션 경계를 어디에 둘 것인지가 굉장히 어려움.
- 확실히 x-lock에서 분산 락을 적용하면, 성능상 이점을 더욱 많이 얻을 수 있었다.
- 하나의 트랜잭션에 포함된 비즈니스 로직에 분산 락 적용을 하면 트랜잭션 경계를 분리하기 위해 더욱 복잡해짐.
  - 따라서 분산 락이 꼭 필요한 것인가에 대한 고민을 하게 되었는데, 어쨌든 x-lock 보단 성능상의 이점을 얻을 수 있기 때문에 도입했지만, 데이터 정합성은 중요하지만 한 번에 요청이 몰리는 경우가 아니라면 x-lock도 충분할 것이라고 생각함. 

### 해당 스텝 이후 (구현)해야할 것

- Redis로 캐시다루기(이후 챕터에서 다룸)
- QueryDSL 도입 후, 인기 상품에 대해 조회하는 API 만들어야함.

### 해보기 전에 내가 알아야 하는 것

- 분산 락과 트랜잭션 경계.
- Redis & 캐싱

### 해당 스텝 이후 할 것

- 라이브세션을 본 후, 놓친 부분이 있다면 구현하기
- 캐싱 구현 -> 다음 챕터에 캐싱 구현됨.

### 라이브 세션

- KV 스토어의 특성 이해하기: 가벼움
  - 가볍다 :
    - 속도가 빠르다 뿐만 아니라, 해당 툴의 복잡도가 낮고, 간단하다는 의미기도 함.
- 분산락 취득/해제와 트랜잭션이 수행되는 타이밍 잘 추적하기
- 캐싱에 대해서는 아무리 깊게 생각해도 과하지 않다.


</details>



<details>
<summary> <b> Step 7. Redis를 활용한 캐싱 </b> </summary>

### 해당 스텝에서 배운 것

- Redis 를 통해서 캐싱을 할 수 있다.
- Redis 를 데이터 스토어로써 보조적인 수단으로 이용하면, 성능을 더욱 향상 시킬 수 있다. 

### 해당 스텝에서 한 것

- 쿠폰 선찬순 발급 시스템 구조 변경
  - 기존
    - 요청 -> Redis 분산락 -> DB 트랜잭션 시작 및 커밋 -> Redis 분산락 해제 -> 응답
  - 현재
    - 요청 -> Redis 로 처리 후 응답
  - 테스트 결과 : 기존 약 25 ~ 30초에서 7~10 초로 성능 250% ~ 400% 증가 

- 인기 상품 API 조회 구현
  - QueryDSL과 Redis를 이용하여, 구현함.


### 해당 스텝에서 얻은 것

- DB보다는 Redis를 적절히 잘 활용하면, 더욱 더 높은 성능을 기대할 수 있음.


### 해당 스텝 이후 (구현)해야할 것

- 판매 건수 순으로 인기상품을 조회하도록 되어있지만, 추후 재구매율 및 조회수에 따라 나오도록 구현

### 해보기 전에 내가 알아야 하는 것

- Redis의 기능이 아직 익숙지 않아서 더 알아봐야할 거 같음.
- 아키텍처 설계 및 구조

### 해당 스텝 이후 할 것



### 라이브 세션

캐싱보단, 레디스라는 툴을 잘 활용하기 위한 부분에 초점에 맞춰진 챕터.

- Redis VS DB 장단점 고려하기
  - Redis는 가볍다.
  - 서비스 중에는 변경하는 것보다 읽기를 할 때가 더욱 빈도가 많다.
  - 따라서 이를 레디스를 활용하면, 성능상의 이점을 얻을 수 있다.
- 정책에 대한 정의를 확실하게 해야한다
  - 기획자와의 정책이 어떤 협의가 되었는지 문서를 남기고 해당 문서에 따라 구현해야함. 
  - 정책이 있지 않으면, 혼잡해진다.
    - 예를 들어,무신사에 랭킹 페이지가 있는데, 해당 페이지에 랭킹의 역순 정렬 기능은 없다. 
    - 정책상 없는 것이다. 정책이 정해져 있지 않으면, 고려하지 않아도 될 것까지 고려하게 된다. 
- 협업에 어떤 선택이 유리할 것인가?
  - Redis를 공부하다보면, 원자적 연산을 지원하는 Lua 스크립트를 알게되고, Lua 스크립트를 사용할 수도 있다.
    - Lua 스크립트는 좋은 기능이다.
    - Redis의 숙련도가 높은 팀원들과 함께 한다면 좋은 기능이지만 Redis의 숙련도가 없는 팀원들과 함꼐 한다면, Lua 스크립트가 좋은 선택이 아닐 수도 있다.
  - 요구사항 외에 뭔가 더 하려고 할 때가 있다.
    - 이런 부분을 좀 참아야 한다.
    - 다만, 경험에 의해서 분명 뭔가 더 추가될 거 같은 느낌은 있다. 그때는 요구사항에 좀 더 곁들이면 되지만, 이 부분은 경험을 통해서 배워야 한다.
  - 무엇이든 정답은 없다.
    - 늘 트레이드 오프를 생각해야한다.

</details>


<details>
<summary> <b> Step 8. 이벤트 기반 아키텍처 도입 </b> </summary>

### 해당 스텝에서 배운 것

- Event 기반 흐름 제어
  - 코드 결합도 감소 
    - Event 발행/구독으로 로직 간 의존성 최소화
  - 관심사 분리
    - 각 서비스는 자신에게 필요한 작업만 수행
    - 각 서비스는 책임에 맞는 것만 수행해야 함.
- 이벤트의 활용 방안
  - 트랜잭션 분리
    - 큰 트랜잭션 -> 여러 작은 트랜잭션으로 분할
    - A 프로세스 실행 후, 이벤트에 의해 B 프로세스가 실행된다고 가정했을 때, 트랜잭션을 분리하면, A에서 문제가 발생해도, B 프로세스에는 영향이 없다. 그 반대도 마찬가지다.
    - 이벤트를 활용하면, 장애 격리도 가능해진다.
  - 후속 작업 Trigger
    - 이벤트 기반으로 후속 로직을 유연하게 설명
  - 장애 격리
    - 외부 작업 실패가 주요 트랜잭션에 영향을 주지 않도록 설계 가능

#### 이벤트

- 어떤 일이 일어났음을 알리는 신호이자, 흐름을 이어주는 트리거
- 구성요소
  - Publisher(Producer) : 이벤트를 생성하는 존재 
  - Event(Message) : 이벤트
  - Listener(Consumer) : 이벤트 소비자
- 만약 프로세스가 마이크로서비스라면?
  - 포인트 차감 -> 결제 정보 저장 -> 주문 상태 변경순으로 프로세스가 진행된다고 가정했을 때, 주문 상태 단계에서 로직이 실패할 경우, 실패 이벤트를 발생시켜서 전 단계를 프로세스를 롤백시키도록 보상 트랜잭션/SAGA 패턴을 고려해야한다. 
- 흐름이 명시적이지 않아서 전체 프로세스를 한눈에 파악하기 어렵다.
- 테스트와 디버깅이 어려워질 수 있다.

### 해당 스텝에서 한 것

- 쿠폰 발행 로직 개선
  - 기존 : Redis로만 저장
  - 개선 : Redis 로 저장된 후, 이벤트를 발행시켜 RDB에 쿠폰 차감 적용 및 사용자 쿠폰 발행 내역 RDB에 저장하는 구조로 개선
- 외부 API로 데이터 전송 구조 개선(실제 외부로 데이터 전송하진 않음)
  - 기존 : 로직 중간에 비동기로 API 데이터 전송하는 구조, 데이터 전송 실패시 Outbox에 저장하는 구조
  - 개선 : 로직 중 outbox에 데이터 저장, 로직이 다 끝난 후, 이벤트를 발행시켜 외부 API로 데이터를 전송, 외부 API로 데이터 전송 완료시 이벤트를 발행시켜 Outbox를 삭제하는 구조로 변경

#### 쿠폰 발행시, 이벤트 처리를 어떻게 할 것인가.

쿠폰을 발행하고, 사용자에게 쿠폰 내역 저장, 쿠폰 개수 차감을 해야하는데, 이를 이벤트로 처리하려고 했다.
쿠폰 발행 후, 이벤트 처리를 하는 차원에서 어떻게 처리해야 하는지가 의문이었다.

두 가지 방식에 대한 고민이 있었는데, 하나는 아래와 같이.

```java
@Component
@RequiredArgsConstructor
public class CouponIssueEventListener {

    private final DecreaseCouponUseCase decreaseCouponUseCase;
    private final RegisterCouponHistoryUseCase registerCouponHistoryUseCase;

    @Async
    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
    public void onCouponIssueCompleted(CouponIssueEvent event) {
        decreaseCouponUseCase.decrease(event.couponId());
    }

    @Async
    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
    public void onMemberIssuedCouponCompleted(CouponIssueEvent event) {
        registerCouponHistoryUseCase.register(event.couponId(), event.memberId());
    }

}
```

하나는 아래와 같이다.

```java
@Component
@RequiredArgsConstructor
public class CouponIssueEventListener {

    private final DecreaseCouponUseCase decreaseCouponUseCase;
    private final RegisterCouponHistoryUseCase registerCouponHistoryUseCase;

    @Async
    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
    public void onCouponIssueCompleted(CouponIssueEvent event) {
        decreaseCouponUseCase.decrease(event.couponId());
        registerCouponHistoryUseCase.register(event.couponId(), event.memberId());
    }

}
```

이 두 가지 방법 중 아래와 같이 해야한다.
왜냐하면, 쿠폰 개수 차감과 쿠폰 발행 내역 생성은 사실 하나의 트랜잭션에서 같이 일어나야 하는 작업이기 때문이다.
이를 통해서 역시 트랜잭션 경계에 대한 중요성을 한 번 더 배우고 간다.


### 해당 스텝에서 얻은 것

- 트랜잭션 경계의 중요성
- 이벤트 처리 기술
  - 트랜잭션 직전, 커밋 후, 롤백 이벤트 등등..
- 보상 트랜잭션 및 SAGA 패턴

### 해당 스텝 이후 (구현)해야할 것



### 해보기 전에 내가 알아야 하는 것

- Event 관련 애너테이션 및 용도

### 해당 스텝 이후 할 것


### 라이브 세션

- 이벤트의 리스크를 인지하고 있는가
- 왜 MSA?
  - MSA의 가장 큰 목적은 관심사의 분리
    - 귀찮지만, 관심사의 분리가 제대로 이루어졌을 때, 얻는 이점이 많기 때문이다.
  - 인지 자원을 더 쓰고, 생각할 수 있는 범위를 줄여서 다루는 건 되게 큰 장점
    - 이렇게 되면, 기능을 구현하고 운영하는 데 있어서 부작용 및 실수의 여지가 줄어든다.
  - 인터페이스(API 엔드포인트) 분리를 함으로써 스펙을 변경하지 않고, 구조 변경 혹은 성능 개선 등의 작업을 수월하게 작업할 수 있음.
  - 시스템 운영 관점에서는 A , B , C 서비스가 있을 떄, A 서비스가 무너져도 B, C 서비스는 살아있을 수 있어, 내구성을 챙길 수 있다. 
- '마이크로 서비스'를 어떻게 정의할 것인가


**이벤트**
- 행위와 행위를 비동기로 분리시키는 것
- 관심사의 분리가 가장 큼.
- 기능 구현은 명확히 책임이 분리되어야 하는데, 기능 외적으로 다른 기능을 같이 구현하는 경우에는 이벤트를 활용할 수 있다.
    - 예를 들어, 콘서트 좌석 예매 기능 구현시 콘서트 좌석 예매 외에 해당 콘서트를 랭킹에 반영하는(?) 코드가 같이 있는 경우, 이벤트를 통해 관심사를 분리할 수 있다.


</details>


<details>
<summary> <b> Step 9. Kafka로 대규모 확장 설계 </b> </summary>

### 해당 스텝에서 배운 것

#### Kafka

- 대규모 실시간 데이터 처리를 위한 분산 메시징 시스템이라면?
- 복잡한 분산 시스템을 위해 설계된 메시징 서비스가 필요하기 때문!
  - 대용량 처리
  - 고가용성
  - 다양한 기능(예시: 메시지 유실 방지) -> offset 기능이 있기 때문에 메시지 유실을 방지할 수 있음.


#### 카프카의 구성 요서

**프로듀서(Producer)**
- 메시지를 카프카 시스템에 발행하는 서비스

**컨슈머(Consumer)**
- 카프카 시스템에 발행된 메시지를 읽어오는 서비스

**컨슈머 그룹(Consumer Group)**
- 토픽에 있는 메시지를 구독하는 단위
  - 컨슈머 단위가 아니라, 컨슈머 그룹으로 토픽 메세지를 구독하게 됨.
- 보통 하나의 서비스를 나타냄
- 메세지가 어떤 파티션에 담길지는 메시지의 키 값에 따라 결정 됨.
- **컨슈머 그룹 개념이 있기 때문에 하나의 토픽에서 발행된 메시지를 여러 서비스에서 독립적으로 읽어갈 수 있다.**

**오프셋(Offset)**
- 컨슈머가 어디까지 메시지를 읽었는지를 기록해둔 데이터
- 예를 들어, 프로듀서가 1,2,3,4,5 개의 메세지를 발행했고, 1,2까지 컨슈머가 받아서 처리했다면, Offset은 2까지 컨슈머가 메세지를 처리했다고 기록해둠.

**브로커(Broker)**
- 브로커 = 카프카 클러스터를 구성하는 물리적인 서버들
  - 물리적인 서버들 = 인스턴스 개념
- 프로듀서에게 메세지를 받아 이를 저장하고 이를 컨슈머로 전송하는 역할
- 특별한 역할을 수행하는 브로거 : Controller, Coordinator
  - Controller  : 브로커 간의 연결을 조정하는 역할을 함.
  - Coordinator : 컨슈머와 실제 내부 Queue를 매칭해주는 역할을 함.
- Bootstrap Server
  - 클라이언트가 카프카 클러스터에 접속하기 위한 진입점이 되는 브로커

**메시지(Message)**
- 카프카를 통해 프로듀서에서 컨슈머로 이동하는 데이터를 의미
- Key, Value로 구성되어 있음(보통은 Key에 리소스ID, Value에 리소스 상세 정보가 담김)

**토픽(Topic)**
- 메세지의 종류를 분류하는 기준이며, 컨슈머는 이 단위로 메세지를 구독함.


**파티션(Partition)**
- 실제 메시지가 담겨있는 큐이며, 토픽은 여러개의 파티션으로 구성되어있음
- 하나의 파티션은 하나의 컨슈머만 사용할 수 있음에 주의
- 메시지가 어떤 파티션에 담길지는 메시지의 키 값에 따라 결정 됨.


**리밸런싱(Rebalancing)**
- 중간에 컨슈머가 추가/삭제 되거나 새로운 파티션이 추가됐을 때, 컨슈머별로 할당된 파티션을 다시 고르게 분배하는 과정이 필요하며, 이를 리밸런싱이라고 함.
- 리밸런싱 중에는 컨슈머가 카프카 시스템으로부터 메시지를 읽을 수 없음에 주의해야 한다.

**클러스터(Cluster)**
- 고가용성과 확장성을 위해 여러 브로커를 묶어 하나의 시스템으로 구성
- 카프카는 운영 도중에 브로커 구성을 변경하여 유연한 스케일링이 가능함.

**Replication**
브로커 중 하나에 갑자기 장애가 생기면?
- 카프카는 다른 브로커에 파티션 복제본(Replica)을 만들어두는 기능을 제공
- Leader Replica vs Follower Replica = 메인용 vs 백업용


#### 외부 API 데이터 전송 실패시

- 원래는 이벤트를 사용할 때는 컨슈머가 수신을 받지 못한 경우, 데이터 전달에 대한 책임, 재전송 로직 등등을 고민해야 하는데, 카프카를 도입하면, 카프카가 알아서 재전송을 해준다.


#### Kafka 관련 키워드

**Auto-commit** vs **Manual-commit**

**DLQ(Dead Letter Queue)**
- 처리할 수 없는 메시지는 어떻게 다루면 좋을까?
- 실패한 메시지를 담아놓는 큐

**리텐션(Retention) 정책**
- 카프카에 들어간 메시지는 영원히 보관될까?

**멱등성(Idempotency)**
- 같은 메시지를 여러 번 읽어도 괜찮은 시스템을 만들 수는 없을까?
- 예를 들어, 잔액에 100원을 올려주는 메시지를 발행했다고 쳤을 때, 커밋의 이슈로 인해 중복된 메시지를 컨슈머가 받을 수도 있다. 1000원이라면, 결과적으로 1100원이 되어야하는데, 중복으로 한 번 더 요청되어서 1200원이 될 수도 있다. 이를 방지하기 위해서 100원을 플러스하는게 아니라, 결과인 1100원을 만들어라는 메시지를 통해서 멱등성을 지켜줄 수 있다.

**Zero-Payload** vs **Full-Payload**
- 카프카 메시지 안에는 어떤 내용을 담으면 좋을까?
- Zero-Payload : key는 두고, value는 비워둔 메시지
- Full-Payload : key, value를 모두 가지고 있는 메시지
 

### 해당 스텝에서 한 것



### 해당 스텝에서 얻은 것



### 해당 스텝 이후 (구현)해야할 것



### 해보기 전에 내가 알아야 하는 것



### 해당 스텝 이후 할 것



### 라이브 세션



</details>


<details>
<summary> <b> Step 10. 장애 대응 프로세스 </b> </summary>

### 해당 스텝에서 배운 것



### 해당 스텝에서 한 것


### 해당 스텝에서 얻은 것



### 해당 스텝 이후 (구현)해야할 것



### 해보기 전에 내가 알아야 하는 것


### 해당 스텝 이후 할 것


### 라이브 세션


</details>