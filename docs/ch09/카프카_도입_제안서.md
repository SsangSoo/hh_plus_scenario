# 카프카 도입 제안서

## 1. 개요

### 1.1 배경

현재 e-commerce 서비스에서는 결제 완료 후 외부 데이터 플랫폼으로 주문 정보를 전송하는 요구사항이 있습니다. 이를 위해 Spring의 `ApplicationEventPublisher`를 활용한 이벤트 기반 아키텍처를 도입하여 트랜잭션과 관심사를 분리하고 있습니다.

현재 구현된 이벤트 처리 방식:
- `@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)`: 트랜잭션 커밋 후 이벤트 처리
- `@Async`: 비동기 처리로 응답 시간 단축
- `@Retryable`: 실패 시 재시도 로직
- `Outbox 패턴`: 외부 전송 실패 시 fallback 처리

### 1.2 현재 이벤트 처리 현황

| 이벤트 | 발행 위치 | 처리 내용 |
|--------|-----------|-----------|
| `PaymentEvent` | PaymentFacade | 결제 완료 → 외부 데이터 플랫폼 전송 |
| `CouponIssueEvent` | IssueCouponService | 쿠폰 발급 → DB 반영 (쿠폰 수량 감소, 이력 저장) |
| `OutboxInfoEvent` | PaymentDataTransportService | 전송 성공 → Outbox 레코드 삭제 |

### 1.3 제안 목적

Spring 이벤트 기반 아키텍처의 **단일 애플리케이션 한계**를 극복하고, **분산 시스템으로 확장** 가능한 Apache Kafka 도입을 제안합니다.

---

## 2. Apache Kafka란?

### 2.1 정의

Apache Kafka는 LinkedIn에서 개발하고 현재 Apache Software Foundation에서 관리하는 **분산 스트리밍 플랫폼**입니다. 대용량의 실시간 데이터 스트림을 높은 처리량과 낮은 지연 시간으로 처리할 수 있습니다.

### 2.2 핵심 특징

1. **분산 시스템**: 여러 브로커에 데이터를 분산 저장하여 확장성과 가용성 확보
2. **내구성**: 디스크에 메시지를 저장하여 데이터 유실 방지
3. **높은 처리량**: 초당 수백만 건의 메시지 처리 가능
4. **실시간 처리**: 밀리초 단위의 낮은 지연 시간
5. **메시지 순서 보장**: 파티션 내에서 메시지 순서 보장

---

## 3. Kafka 구성 요소

### 3.1 핵심 구성 요소

```
┌─────────────────────────────────────────────────────────────────┐
│                        Kafka Cluster                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Broker 1   │  │  Broker 2   │  │  Broker 3   │              │
│  │  ┌───────┐  │  │  ┌───────┐  │  │  ┌───────┐  │              │
│  │  │Topic A│  │  │  │Topic A│  │  │  │Topic B│  │              │
│  │  │Part 0 │  │  │  │Part 1 │  │  │  │Part 0 │  │              │
│  │  └───────┘  │  │  └───────┘  │  │  └───────┘  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │                      ZooKeeper                               ││
│  └─────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────┘

     ▲                                                    │
     │ Produce                                   Consume  ▼

┌──────────┐                                      ┌──────────────┐
│ Producer │                                      │ Consumer     │
│ (서비스)  │                                      │ (데이터플랫폼) │
└──────────┘                                      └──────────────┘
```

| 구성 요소 | 설명 |
|-----------|------|
| **Producer** | 메시지를 생성하고 Topic에 전송하는 주체 |
| **Consumer** | Topic에서 메시지를 읽어 처리하는 주체 |
| **Broker** | Kafka 서버, 메시지를 저장하고 관리 |
| **Topic** | 메시지를 구분하는 논리적 채널 (카테고리) |
| **Partition** | Topic을 물리적으로 분할한 단위, 병렬 처리 가능 |
| **Consumer Group** | 여러 Consumer를 그룹화하여 메시지를 분산 처리 |
| **ZooKeeper** | 클러스터 메타데이터 관리 (Kafka 3.x부터 KRaft로 대체 가능) |

### 3.2 메시지 흐름

```
1. Producer가 메시지 생성
         ↓
2. Topic의 특정 Partition에 메시지 저장
         ↓
3. Broker가 메시지를 디스크에 영속화
         ↓
4. Consumer가 Partition에서 메시지 읽기
         ↓
5. Consumer가 offset 커밋 (처리 완료 표시)
```

### 3.3 대표적인 기능

| 기능 | 설명 |
|------|------|
| **Pub/Sub 메시징** | 발행-구독 패턴으로 느슨한 결합 |
| **메시지 저장** | 설정된 보존 기간 동안 메시지 저장 |
| **메시지 리플레이** | offset 조정으로 과거 메시지 재처리 가능 |
| **정확히 한 번 전달** | Exactly-once semantics 지원 |
| **스트림 처리** | Kafka Streams로 실시간 데이터 처리 |

---

## 4. Kafka 장단점

### 4.1 장점

| 장점 | 설명 |
|------|------|
| **높은 처리량** | 배치 처리, 압축, 제로 카피로 초당 수백만 건 처리 가능 |
| **확장성** | 브로커 추가만으로 수평 확장 가능 |
| **내구성** | 복제 팩터 설정으로 데이터 유실 방지 |
| **분산 처리** | 파티션 기반 병렬 처리로 부하 분산 |
| **느슨한 결합** | Producer와 Consumer 간 독립성 보장 |
| **메시지 영속성** | 디스크 저장으로 장애 복구 가능 |
| **재처리 가능** | offset 기반으로 메시지 재처리 지원 |
| **실시간 + 배치** | 스트림 처리와 배치 처리 모두 지원 |

### 4.2 단점

| 단점 | 설명 | 해결 방안 |
|------|------|----------|
| **운영 복잡성** | ZooKeeper/KRaft, 브로커 관리 필요 | 관리형 서비스(AWS MSK, Confluent Cloud) 활용 |
| **학습 곡선** | 파티션, 오프셋, 컨슈머 그룹 등 개념 이해 필요 | 단계적 도입 및 팀 교육 |
| **지연 시간** | 배치 처리로 밀리초 단위 지연 발생 가능 | 설정 튜닝 (linger.ms, batch.size) |
| **메시지 순서** | 파티션 간 순서 보장 안됨 | 동일 키로 파티션 고정 |
| **리소스 소모** | 메모리, 디스크 자원 필요 | 적절한 리소스 프로비저닝 |

---

## 5. 현재 시스템에서 Kafka로의 확장

### 5.1 현재 Spring 이벤트 방식의 한계

```
┌─────────────────────────────────────────────────────────┐
│                    단일 애플리케이션                      │
│                                                         │
│  PaymentFacade ──publish──▶ ApplicationEventPublisher   │
│                                      │                  │
│                                      ▼                  │
│                            PaymentEventListener         │
│                                      │                  │
│                                      ▼                  │
│                         PaymentDataTransportService     │
│                                      │                  │
│                                      ▼                  │
│                            [외부 데이터 플랫폼]           │
└─────────────────────────────────────────────────────────┘
```

**한계점:**
1. **단일 인스턴스 종속**: 이벤트가 동일 JVM 내에서만 전파
2. **확장성 제한**: 다중 인스턴스 환경에서 이벤트 공유 불가
3. **장애 복구 어려움**: 애플리케이션 재시작 시 처리 중인 이벤트 유실 가능
4. **MSA 전환 어려움**: 서비스 분리 시 이벤트 전파 메커니즘 재구현 필요

### 5.2 Kafka 도입 후 아키텍처

```
┌────────────────┐     ┌────────────────┐     ┌────────────────┐
│   Order API    │     │  Payment API   │     │   Coupon API   │
│   Instance 1   │     │   Instance 1   │     │   Instance 1   │
└───────┬────────┘     └───────┬────────┘     └───────┬────────┘
        │                      │                      │
        │ Produce              │ Produce              │ Produce
        ▼                      ▼                      ▼
┌─────────────────────────────────────────────────────────────────┐
│                        Kafka Cluster                             │
│                                                                  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐           │
│  │ payment-     │  │ coupon-      │  │ order-       │           │
│  │ completed    │  │ issued       │  │ created      │           │
│  └──────────────┘  └──────────────┘  └──────────────┘           │
└─────────────────────────────────────────────────────────────────┘
        │                      │                      │
        │ Consume              │ Consume              │ Consume
        ▼                      ▼                      ▼
┌────────────────┐     ┌────────────────┐     ┌────────────────┐
│ Data Platform  │     │ Notification   │     │ Analytics      │
│   Consumer     │     │   Service      │     │   Service      │
└────────────────┘     └────────────────┘     └────────────────┘
```

### 5.3 이벤트 기반 아키텍처의 전체 시스템 확장

현재 구현된 **PaymentEvent**, **CouponIssueEvent** 등의 이벤트를 Kafka 토픽으로 확장하면:

| 현재 이벤트 | Kafka 토픽 | 확장 가능한 Consumer |
|-------------|-----------|---------------------|
| `PaymentEvent` | `payment-completed` | 데이터 플랫폼, 알림 서비스, 정산 서비스 |
| `CouponIssueEvent` | `coupon-issued` | 쿠폰 히스토리, 마케팅 분석, 사용자 알림 |
| (추가) `OrderCreatedEvent` | `order-created` | 재고 관리, 배송 서비스, 분석 서비스 |
| (추가) `StockDeductedEvent` | `stock-deducted` | 재고 알림, 발주 시스템 |

### 5.4 Outbox 패턴과 Kafka 연동

현재 구현된 Outbox 패턴을 Kafka와 연동하면 **Transactional Outbox 패턴**으로 발전시킬 수 있습니다:

```
┌─────────────────────────────────────────────────────────────────┐
│                      Payment Service                             │
│                                                                  │
│  1. 결제 처리 + Outbox 저장 (동일 트랜잭션)                       │
│     ┌─────────────────────┐                                     │
│     │ BEGIN TRANSACTION   │                                     │
│     │ - Payment 저장      │                                     │
│     │ - Outbox 저장       │                                     │
│     │ COMMIT              │                                     │
│     └─────────────────────┘                                     │
│                                                                  │
│  2. Outbox Relay (별도 프로세스)                                  │
│     Outbox 테이블 → Kafka Producer → payment-completed 토픽     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**장점:**
- 트랜잭션과 메시지 발행의 원자성 보장
- 메시지 유실 방지
- 최소 한 번 전달(At-least-once) 보장

---

## 6. Kafka 도입 시 기대 효과

### 6.1 시스템 확장성 향상

| 항목 | 현재 (Spring Event) | Kafka 도입 후 |
|------|---------------------|---------------|
| 다중 인스턴스 | 이벤트 공유 불가 | Consumer Group으로 자동 분산 처리 |
| 서비스 분리 | 이벤트 전파 불가 | 토픽 기반 느슨한 결합 |
| 처리량 | JVM 메모리 제한 | 파티션 확장으로 무제한 확장 |

### 6.2 장애 내성 강화

- **메시지 영속성**: Kafka가 메시지를 디스크에 저장하여 유실 방지
- **Consumer 장애 복구**: offset 기반으로 마지막 처리 지점부터 재개
- **Producer 장애 복구**: acks 설정으로 메시지 전송 보장

### 6.3 MSA 전환 기반 마련

현재 모놀리식 구조에서 MSA로 전환 시:
- 도메인별 서비스 분리 (Order, Payment, Coupon, Stock 등)
- Kafka를 통한 서비스 간 비동기 통신
- 각 서비스의 독립적인 배포 및 확장

### 6.4 대용량 트래픽 대응

선착순 쿠폰 발급, 인기 상품 조회 등 **대용량 요청이 발생하는 지점**에서:
- 요청을 Kafka 큐에 적재하여 순차 처리
- Consumer 수 조절로 처리량 조절
- 피크 트래픽 완화 (Traffic Smoothing)

---

## 7. 도입 제안

### 7.1 단계별 도입 계획

| 단계 | 내용 | 기대 효과 |
|------|------|----------|
| **1단계** | 로컬 환경에 Kafka 설치 및 기본 실습 | 팀원들의 Kafka 이해도 향상 |
| **2단계** | 결제 완료 이벤트를 Kafka로 전환 | 기존 기능 유지하며 Kafka 검증 |
| **3단계** | 쿠폰 발급 이벤트를 Kafka로 전환 | 대용량 트래픽 처리 검증 |
| **4단계** | 추가 이벤트 토픽 설계 및 구현 | 전체 시스템 확장 |

### 7.2 기술 스택

| 구성 요소 | 선택지 | 권장 |
|-----------|--------|------|
| Kafka 설치 | Docker Compose | 개발 환경에서 빠른 구축 |
| Kafka 클라이언트 | Spring Kafka | Spring Boot와 자연스러운 통합 |
| 직렬화 | JSON (Jackson) | 가독성 및 디버깅 용이 |
| 운영 환경 | AWS MSK | 관리형 서비스로 운영 부담 최소화 |

---

## 8. 결론

현재 Spring 이벤트 기반 아키텍처는 단일 애플리케이션 내에서 트랜잭션과 관심사 분리에 효과적입니다. 그러나 서비스 규모가 확장되고 MSA로 전환할 경우, **이벤트의 아이디어를 전체 시스템으로 확장**하기 위해 Apache Kafka 도입이 필요합니다.

Kafka를 도입하면:
1. **현재 이벤트 처리 로직을 그대로 활용**하면서 분산 시스템으로 확장
2. **높은 처리량과 내구성**으로 대용량 트래픽 대응
3. **느슨한 결합**으로 서비스 독립성 확보
4. **MSA 전환의 기술적 기반** 마련

따라서 팀 내 Kafka 기초 학습을 진행하고, 단계적으로 현재 이벤트 처리를 Kafka로 전환할 것을 제안합니다.

---

**작성일**: 2026-02-22
